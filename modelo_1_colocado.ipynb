{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\jeffe\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
      "     -------------------------------------- 81.9/81.9 kB 416.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\jeffe\\anaconda3\\lib\\site-packages (from category_encoders) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\jeffe\\anaconda3\\lib\\site-packages (from category_encoders) (0.24.1)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\jeffe\\anaconda3\\lib\\site-packages (from category_encoders) (1.2.4)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\jeffe\\anaconda3\\lib\\site-packages (from category_encoders) (0.12.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\jeffe\\anaconda3\\lib\\site-packages (from category_encoders) (1.6.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\jeffe\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\jeffe\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\jeffe\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2021.1)\n",
      "Requirement already satisfied: six in c:\\users\\jeffe\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jeffe\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jeffe\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\jeffe\\anaconda3\\lib\\site-packages (from importlib-resources->category_encoders) (3.4.1)\n",
      "Installing collected packages: importlib-resources, category_encoders\n",
      "Successfully installed category_encoders-2.6.3 importlib-resources-6.1.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install category_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "\n",
    "# Modelos\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"../Desafio_interno_visagio/Data/Dataset_Treino.csv\")\n",
    "resp = pd.read_csv(\"../Desafio_interno_visagio/Data/Dataset_Resposta.csv\")\n",
    "sample = pd.read_csv(\"../Desafio_interno_visagio/Data/Sample_Submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verificando dados ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Municipio                  5\n",
       "ID_Aluno                   0\n",
       "Disponibilidade_Tutoria    0\n",
       "Dias_Espera_Inicio         0\n",
       "Dias_Espera_Aprovacao      0\n",
       "Data_Inscrição             0\n",
       "Horario_Estudando          0\n",
       "Conheceu_PROA              0\n",
       "Renda_Familiar             0\n",
       "Pessoas_Casa               0\n",
       "Disponibilidade_3_Meses    0\n",
       "Recursos                   0\n",
       "Idade                      0\n",
       "Aprender_EAD               0\n",
       "Concluiu_EAD               0\n",
       "Estudando                  0\n",
       "Trabalhando                0\n",
       "Estado                     0\n",
       "Escolaridade               0\n",
       "Tipo_escola                0\n",
       "Abandono_curso             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Municipio                  6\n",
       "ID_Aluno                   0\n",
       "Disponibilidade_Tutoria    0\n",
       "Dias_Espera_Aprovacao      0\n",
       "Data_Inscrição             0\n",
       "Horario_Estudando          0\n",
       "Conheceu_PROA              0\n",
       "Renda_Familiar             0\n",
       "Pessoas_Casa               0\n",
       "Disponibilidade_3_Meses    0\n",
       "Recursos                   0\n",
       "Idade                      0\n",
       "Aprender_EAD               0\n",
       "Concluiu_EAD               0\n",
       "Estudando                  0\n",
       "Trabalhando                0\n",
       "Estado                     0\n",
       "Escolaridade               0\n",
       "Tipo_escola                0\n",
       "Dias_Espera_Inicio         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tratando dados ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# conjunto de treinamento\n",
    "atributos_com_nulos = ['Estudando', 'Recursos']\n",
    "for col in atributos_com_nulos:\n",
    "    valor_mais_frequente = dados[col].mode()[0]\n",
    "    dados[col] = dados[col].fillna(valor_mais_frequente)\n",
    "\n",
    "# conjunto de teste\n",
    "atributos_com_nulos = ['Estudando', 'Concluiu_EAD', 'Recursos']\n",
    "for col in atributos_com_nulos:\n",
    "    valor_mais_frequente = resp[col].mode()[0]\n",
    "    resp[col] = resp[col].fillna(valor_mais_frequente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removendo as colunas **Conheceu_PROA** e **Municipio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.drop(labels=['Conheceu_PROA', 'Municipio'], axis=1, inplace=True)\n",
    "resp.drop(labels=['Conheceu_PROA', 'Municipio'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tratando dados datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['Data_Inscrição'] = pd.to_datetime(dados['Data_Inscrição'].str.strip(), format='%d/%m/%Y')\n",
    "dados['Data_Inscrição'] = dados['Data_Inscrição'].apply(lambda x: int(x.timestamp() * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp['Data_Inscrição'] = pd.to_datetime(resp['Data_Inscrição'].str.strip(), format='%d/%m/%Y')\n",
    "resp['Data_Inscrição'] = resp['Data_Inscrição'].apply(lambda x: int(x.timestamp() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalonamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tipos de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ID_Aluno  \n",
    "> Data_Inscrição  \n",
    "\n",
    "Atributos binários:  \n",
    "> Tipo_escola  \n",
    "> Trabalhando  \n",
    "> Estudando  \n",
    "> Disponibilidade_Tutoria  \n",
    "> Disponibilidade_3_Meses  \n",
    "\n",
    "Atributos numéricos:  \n",
    "> Idade  \n",
    "> Pessoas_Casa  \n",
    "> Dias_Espera_Aprovacao  \n",
    "> Dias_Espera_Inicio   \n",
    "\n",
    "Atributos categóricos:  \n",
    "> Horario_Estudando (Nominal)  \n",
    "> Conheceu_PROA (Nominal)    \n",
    "> Municipio (Nominal)  \n",
    "> Estado (Nominal)    \n",
    "> Concluiu_EAD (Nominal)  \n",
    "> Renda_Familiar (Ordinal)  \n",
    "> Escolaridade (Ordinal)  \n",
    "> Aprender_EAD (Ordinal)  \n",
    "> Recursos (Ordinal)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Atributos binários"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Escalonar os atributos binários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['Tipo_escola'].replace(to_replace=['public', 'scholarship'], value=[0, 1], inplace=True)\n",
    "dados['Trabalhando'].replace(to_replace=['Não', 'Sim'], value=[0, 1], inplace=True)\n",
    "dados['Estudando'].replace(to_replace=['Não', 'Sim'], value=[0, 1], inplace=True)\n",
    "dados['Disponibilidade_Tutoria'].replace(to_replace=['Não', 'Sim'], value=[0, 1], inplace=True)\n",
    "dados['Disponibilidade_3_Meses'].replace(to_replace=['Não', 'Sim'], value=[0, 1], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp['Tipo_escola'].replace(to_replace=['public', 'scholarship'], value=[0, 1], inplace=True)\n",
    "resp['Trabalhando'].replace(to_replace=['Não', 'Sim'], value=[0, 1], inplace=True)\n",
    "resp['Estudando'].replace(to_replace=['Não', 'Sim'], value=[0, 1], inplace=True)\n",
    "resp['Disponibilidade_Tutoria'].replace(to_replace=['Não', 'Sim'], value=[0, 1], inplace=True)\n",
    "resp['Disponibilidade_3_Meses'].replace(to_replace=['Não', 'Sim'], value=[0, 1], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Atributos numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tratando os dados do atributo **Pessoas_Casa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['Pessoas_Casa'].replace(to_replace=['Mais que 10'], value=[11], inplace=True)\n",
    "resp['Pessoas_Casa'].replace(to_replace=['Mais que 10'], value=[11], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['Pessoas_Casa'] = dados['Pessoas_Casa'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inicializando o objeto **transformador**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformador = MinMaxScaler().fit(dados[['Idade',\n",
    "'Pessoas_Casa',\n",
    "'Dias_Espera_Aprovacao',\n",
    "'Dias_Espera_Inicio']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Escalonando dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_num_escalonados = transformador.transform(dados[['Idade',\n",
    "'Pessoas_Casa',\n",
    "'Dias_Espera_Aprovacao',\n",
    "'Dias_Espera_Inicio']])\n",
    "\n",
    "X_treino_num_proc = pd.DataFrame(dados_num_escalonados, \n",
    "                                      columns=['Idade',\n",
    "                                                'Pessoas_Casa',\n",
    "                                                'Dias_Espera_Aprovacao',\n",
    "                                                'Dias_Espera_Inicio'],\n",
    "                                        index=dados.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Escalonando dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_num_escalonados = transformador.transform(resp[['Idade',\n",
    "'Pessoas_Casa',\n",
    "'Dias_Espera_Aprovacao',\n",
    "'Dias_Espera_Inicio']])\n",
    "\n",
    "X_validador_num_proc = pd.DataFrame(dados_num_escalonados, \n",
    "                                      columns=['Idade',\n",
    "                                        'Pessoas_Casa',\n",
    "                                        'Dias_Espera_Aprovacao',\n",
    "                                        'Dias_Espera_Inicio'],\n",
    "                                        index=resp.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Atributos categóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cardinalidade dos atributos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recursos             51\n",
       "Renda_Familiar        6\n",
       "Horario_Estudando     5\n",
       "Concluiu_EAD          5\n",
       "Escolaridade          5\n",
       "Estado                4\n",
       "Aprender_EAD          4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados[[\n",
    "     'Horario_Estudando',\n",
    " 'Estado',\n",
    " 'Concluiu_EAD',\n",
    " 'Renda_Familiar',\n",
    " 'Escolaridade',\n",
    " 'Aprender_EAD',\n",
    " 'Recursos'\n",
    "]].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ordinal na **Renda_Familiar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento personalizado\n",
    "mapeamento_personalizado = {\n",
    "    'Até 1 salário mínimo (até R$1.100)':0.1,\n",
    " 'Entre 1 e 2 salários mínimos (R$1.100 – R$2.200)':0.2,\n",
    " 'Entre 2 e 3 salários mínimos (R$2.200 – R$3.300)':0.3,\n",
    " 'Entre 4 e 5 salários mínimos (R$4.400 – R$5.500)':0.5,\n",
    " 'Entre 3 e 4 salários mínimos (R$3.300 – R$4.400)':0.4,\n",
    " 'Mais que 5 salários mínimos (mais que R$5.500)':0.6\n",
    "}\n",
    "\n",
    "# Aplicar a codificação usando o mapeamento\n",
    "dados['Renda_Familiar'] = dados['Renda_Familiar'].map(mapeamento_personalizado)\n",
    "resp['Renda_Familiar'] = resp['Renda_Familiar'].map(mapeamento_personalizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ordinal na **Escolaridade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento personalizado\n",
    "mapeamento_personalizado = {\n",
    "'Cursando o 3º ano do Ensino Médio' :0.1,\n",
    "'Cursando o Ensino Superior':0.4,\n",
    " 'Ensino Médio concluído e não estudando' :0.2,\n",
    " 'Ensino Médio concluído':0.3,\n",
    " 'Ensino Superior concluído':0.5\n",
    "}\n",
    "\n",
    "# Aplicar a codificação usando o mapeamento\n",
    "dados['Escolaridade'] = dados['Escolaridade'].map(mapeamento_personalizado)\n",
    "resp['Escolaridade'] = resp['Escolaridade'].map(mapeamento_personalizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ordinal na **Aprender_EAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento personalizado\n",
    "mapeamento_personalizado = {\n",
    "'Não sei dizer':0.3,\n",
    " 'Muito eu tenho uma rotina definida para participar de cursos a distância':0.4,\n",
    " 'Eu prefiro cursos presenciais' :0.1,\n",
    " 'Quase nada':0.2\n",
    "}\n",
    "\n",
    "# Aplicar a codificação usando o mapeamento\n",
    "dados['Aprender_EAD'] = dados['Aprender_EAD'].map(mapeamento_personalizado)\n",
    "resp['Aprender_EAD'] = resp['Aprender_EAD'].map(mapeamento_personalizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aplicando OrdinalEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o TargetEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "colunas_a_codificar = [['Horario_Estudando',\n",
    "'Estado',\n",
    "'Concluiu_EAD',\n",
    "'Recursos']]\n",
    "\n",
    "# Iterar sobre as colunas especificadas e codificar cada uma\n",
    "for coluna in colunas_a_codificar:\n",
    "    dados[coluna] = encoder.fit_transform(dados[coluna])\n",
    "\n",
    "\n",
    "for coluna in colunas_a_codificar:\n",
    "    resp[coluna] = encoder.fit_transform(resp[coluna])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fazendo o merge dos atributos sem os atributos **ID_Aluno** e **Data_inscrição**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino_escalonado = pd.merge(\n",
    "    dados[[\n",
    " 'Tipo_escola',\n",
    " 'Trabalhando',\n",
    " 'Estudando',\n",
    " 'Disponibilidade_Tutoria',\n",
    " 'Disponibilidade_3_Meses' \n",
    "    ]].reset_index(),\n",
    "    X_treino_num_proc.reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "X_treino_escalonado1 = pd.merge(\n",
    "    X_treino_escalonado,\n",
    "    dados['Renda_Familiar'].reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "X_treino_escalonado2 = pd.merge(\n",
    "    X_treino_escalonado1,\n",
    "    dados['Escolaridade'].reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "X_treino_escalonado3 = pd.merge(\n",
    "    X_treino_escalonado2,\n",
    "    dados['Aprender_EAD'].reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "X_treino_escalonado5 = pd.merge(\n",
    "    X_treino_escalonado3,\n",
    "    dados[coluna].reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "X_treino_escalonado8 = pd.merge(\n",
    "    X_treino_escalonado5,\n",
    "    dados['Data_Inscrição'].reset_index()\n",
    ")\n",
    "\n",
    "X_treino_escalonado8.drop(labels=['index'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validador_escalonado = pd.merge(\n",
    "    resp[[\n",
    " 'Tipo_escola',\n",
    " 'Trabalhando',\n",
    " 'Estudando',\n",
    " 'Disponibilidade_Tutoria',\n",
    " 'Disponibilidade_3_Meses' \n",
    "    ]].reset_index(),\n",
    "    X_validador_num_proc.reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "X_validador_escalonado1 = pd.merge(\n",
    "    X_validador_escalonado,\n",
    "    resp['Renda_Familiar'].reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "X_validador_escalonado2 = pd.merge(\n",
    "    X_validador_escalonado1,\n",
    "    resp['Escolaridade'].reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "X_validador_escalonado3 = pd.merge(\n",
    "    X_validador_escalonado2,\n",
    "    resp['Aprender_EAD'].reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "X_validador_escalonado5 = pd.merge(\n",
    "    X_validador_escalonado3,\n",
    "    resp[coluna].reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "X_validador_escalonado8 = pd.merge(\n",
    "    X_validador_escalonado5,\n",
    "    resp['Data_Inscrição'].reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "X_validador_escalonado8.drop(labels=['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule a média das colunas\n",
    "media_das_colunas = X_treino_escalonado8['Estudando'].median()\n",
    "\n",
    "# Substitua os valores ausentes das colunas pela média respectiva\n",
    "X_treino_escalonado8['Estudando'] = X_treino_escalonado8['Estudando'].fillna(media_das_colunas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "615\n",
    "# 123 iterações = 10 minutos e 28.6 segundos\n",
    "# 4375000 iterações totais\n",
    "# 10 iterações = 14.7 segundos\n",
    "search_space = {\n",
    "    'max_depth': Integer(8,20),\n",
    "    'learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'subsample': Real(0.5, 1.0),\n",
    "    'colsample_bytree': Real(0.5, 1.0),\n",
    "    'colsample_bylevel': Real(0.5, 1.0),\n",
    "    'colsample_bynode' : Real(0.5, 1.0),\n",
    "    'reg_alpha': Real(0.0, 10.0),\n",
    "    'reg_lambda': Real(0.0, 10.0),\n",
    "    'gamma': Real(0.0, 10.0)\n",
    "}\n",
    "\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "opt = BayesSearchCV(xgb.XGBClassifier(), search_space, cv=3, n_iter=123, scoring= ftwo_scorer, \n",
    "                    random_state=8).fit(X_treino_escalonado8, dados['Abandono_curso'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('colsample_bylevel', 1.0),\n",
       "             ('colsample_bynode', 0.6555590530528685),\n",
       "             ('colsample_bytree', 1.0),\n",
       "             ('gamma', 2.5312720195633127),\n",
       "             ('learning_rate', 1.0),\n",
       "             ('max_depth', 20),\n",
       "             ('reg_alpha', 10.0),\n",
       "             ('reg_lambda', 4.332080712683039),\n",
       "             ('subsample', 0.654538364129673)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
       "              colsample_bynode=0.6555590530528685, colsample_bytree=1.0,\n",
       "              enable_categorical=False, gamma=2.5312720195633127, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=1.0, max_delta_step=0, max_depth=20,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=10.0, reg_lambda=4.332080712683039,\n",
       "              scale_pos_weight=1, subsample=0.654538364129673,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncolsample_bylevel= 1.0,\\n             colsample_bynode= 0.6555590530528685,\\n             colsample_bytree= 1.0,\\n             gamma= 2.5312720195633127,\\n             learning_rate= 1.0,\\n             max_depth= 20,\\n             reg_alpha= 10.0,\\n             reg_lambda= 4.332080712683039,\\n             subsample= 0.654538364129673\\n\\n\\n\\nbase_score=0.5, booster='gbtree', colsample_bylevel=1.0,\\n              colsample_bynode=0.6555590530528685, colsample_bytree=1.0,\\n              enable_categorical=False, gamma=2.5312720195633127, gpu_id=-1,\\n              importance_type=None, interaction_constraints='',\\n              learning_rate=1.0, max_delta_step=0, max_depth=20,\\n              min_child_weight=1, missing=nan, monotone_constraints='()',\\n              n_estimators=100, n_jobs=8, num_parallel_tree=1, predictor='auto',\\n              random_state=0, reg_alpha=10.0, reg_lambda=4.332080712683039,\\n              scale_pos_weight=1, subsample=0.654538364129673,\\n              tree_method='exact', validate_parameters=1, verbosity=None\\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = xgb.XGBClassifier(random_state=8, colsample_bylevel= 1.0,\n",
    "             colsample_bynode= 0.6555590530528685,\n",
    "             colsample_bytree= 1.0,\n",
    "             gamma= 2.5312720195633127,\n",
    "             learning_rate= 1.0,\n",
    "             max_depth= 20,\n",
    "             reg_alpha= 10.0,\n",
    "             reg_lambda= 4.332080712683039,\n",
    "             subsample= 0.654538364129673)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "colsample_bylevel= 1.0,\n",
    "             colsample_bynode= 0.6555590530528685,\n",
    "             colsample_bytree= 1.0,\n",
    "             gamma= 2.5312720195633127,\n",
    "             learning_rate= 1.0,\n",
    "             max_depth= 20,\n",
    "             reg_alpha= 10.0,\n",
    "             reg_lambda= 4.332080712683039,\n",
    "             subsample= 0.654538364129673\n",
    "\n",
    "\n",
    "\n",
    "base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
    "              colsample_bynode=0.6555590530528685, colsample_bytree=1.0,\n",
    "              enable_categorical=False, gamma=2.5312720195633127, gpu_id=-1,\n",
    "              importance_type=None, interaction_constraints='',\n",
    "              learning_rate=1.0, max_delta_step=0, max_depth=20,\n",
    "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
    "              random_state=0, reg_alpha=10.0, reg_lambda=4.332080712683039,\n",
    "              scale_pos_weight=1, subsample=0.654538364129673,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:49:53] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
       "              colsample_bynode=0.6555590530528685, colsample_bytree=1.0,\n",
       "              enable_categorical=False, gamma=2.5312720195633127, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=1.0, max_delta_step=0, max_depth=20,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=8, reg_alpha=10.0, reg_lambda=4.332080712683039,\n",
       "              scale_pos_weight=1, subsample=0.654538364129673,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(X_treino_escalonado8, dados['Abandono_curso'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando o submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'ID_Aluno': resp.ID_Aluno,\n",
    "     'Abandono_curso': modelo.predict(X_validador_escalonado8) }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission_xgboost_otimizado7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver = pd.read_csv(\"submission_xgboost_otimizado7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1155\n",
       "0      83\n",
       "Name: Abandono_curso, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver.Abandono_curso.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
